#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®‰è£…éªŒè¯è„šæœ¬
ç”¨äºéªŒè¯å¤šæ¨¡æ€AIç³»ç»Ÿæ˜¯å¦æ­£ç¡®å®‰è£…å’Œé…ç½®
"""

import sys
import traceback
from pathlib import Path

def check_imports():
    """æ£€æŸ¥æ ¸å¿ƒæ¨¡å—å¯¼å…¥"""
    print("ğŸ” æ£€æŸ¥æ¨¡å—å¯¼å…¥...")
    
    try:
        # æ£€æŸ¥åŸºç¡€ä¾èµ–
        import torch
        print(f"âœ… PyTorch {torch.__version__}")
        
        import numpy as np
        print(f"âœ… NumPy {np.__version__}")
        
        # æ£€æŸ¥é…ç½®æ¨¡å—
        from config.model_config import ModelConfig
        print("âœ… é…ç½®æ¨¡å—")
        
        # æ£€æŸ¥æ¨¡å‹æ¨¡å—
        from src.models.multimodal_ai import MultiModalAI
        print("âœ… ä¸»æ¨¡å‹")
        
        from src.models.text_model import TextEncoder, TextDecoder
        print("âœ… æ–‡æœ¬æ¨¡å‹")
        
        from src.models.audio_model import AudioEncoder
        print("âœ… éŸ³é¢‘æ¨¡å‹")
        
        from src.models.vision_model import VisionEncoder
        print("âœ… è§†è§‰æ¨¡å‹")
        
        from src.models.fusion_model import MultiModalFusion
        print("âœ… èåˆæ¨¡å‹")
        
        # æ£€æŸ¥æ•°æ®æ¨¡å—
        from src.data.tokenizer import SimpleTokenizer
        print("âœ… åˆ†è¯å™¨")
        
        from src.data.dataset import MultiModalDataset
        print("âœ… æ•°æ®é›†")
        
        from src.data.preprocessor import DataPreprocessor
        print("âœ… æ•°æ®é¢„å¤„ç†å™¨")
        
        # æ£€æŸ¥APIæ¨¡å—
        from src.api.chat_api import ChatAPI
        print("âœ… èŠå¤©API")
        
        # æ£€æŸ¥å·¥å…·æ¨¡å—
        from src.utils.logger import get_logger
        print("âœ… æ—¥å¿—å·¥å…·")
        
        from src.utils.metrics import MetricsTracker
        print("âœ… è¯„ä¼°æŒ‡æ ‡")
        
        from src.utils.helpers import count_parameters
        print("âœ… è¾…åŠ©å·¥å…·")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        return False
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        traceback.print_exc()
        return False


def check_model_creation():
    """æ£€æŸ¥æ¨¡å‹åˆ›å»º"""
    print("\nğŸ—ï¸ æ£€æŸ¥æ¨¡å‹åˆ›å»º...")
    
    try:
        from config.model_config import ModelConfig
        from src.models.multimodal_ai import MultiModalAI
        from src.utils.helpers import count_parameters
        
        # åˆ›å»ºé…ç½®
        config = ModelConfig()
        print(f"âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæ¨¡å‹
        model = MultiModalAI(config)
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è®¡ç®—å‚æ•°é‡
        total_params = count_parameters(model)
        trainable_params = count_parameters(model, trainable_only=True)
        
        print(f"âœ… æ€»å‚æ•°é‡: {total_params:,}")
        print(f"âœ… å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        # æ£€æŸ¥æ¨¡å‹ç»„ä»¶
        assert hasattr(model, 'text_encoder'), "ç¼ºå°‘æ–‡æœ¬ç¼–ç å™¨"
        assert hasattr(model, 'audio_encoder'), "ç¼ºå°‘éŸ³é¢‘ç¼–ç å™¨"
        assert hasattr(model, 'vision_encoder'), "ç¼ºå°‘è§†è§‰ç¼–ç å™¨"
        assert hasattr(model, 'fusion'), "ç¼ºå°‘èåˆå±‚"
        assert hasattr(model, 'text_decoder'), "ç¼ºå°‘æ–‡æœ¬è§£ç å™¨"
        
        print("âœ… æ¨¡å‹ç»„ä»¶å®Œæ•´")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        traceback.print_exc()
        return False


def check_data_processing():
    """æ£€æŸ¥æ•°æ®å¤„ç†"""
    print("\nğŸ“Š æ£€æŸ¥æ•°æ®å¤„ç†...")
    
    try:
        import torch
        from config.model_config import ModelConfig
        from src.data.tokenizer import SimpleTokenizer
        from src.data.dataset import DialogueDataGenerator
        from src.data.preprocessor import DataPreprocessor
        
        config = ModelConfig()
        
        # æ£€æŸ¥åˆ†è¯å™¨
        tokenizer = SimpleTokenizer(config.vocab_size)
        text = "ä½ å¥½ä¸–ç•Œ"
        tokens = tokenizer.encode(text)
        decoded = tokenizer.decode(tokens)
        print(f"âœ… åˆ†è¯å™¨: '{text}' -> {tokens} -> '{decoded}'")
        
        # æ£€æŸ¥æ•°æ®ç”Ÿæˆå™¨
        generator = DialogueDataGenerator(config)
        sample = generator.generate_multimodal_sample()
        print(f"âœ… æ•°æ®ç”Ÿæˆå™¨: ç”Ÿæˆæ ·æœ¬åŒ…å« {list(sample.keys())}")
        
        # æ£€æŸ¥æ•°æ®é¢„å¤„ç†å™¨
        preprocessor = DataPreprocessor(config)
        text = "æµ‹è¯•æ–‡æœ¬"
        result = preprocessor.preprocess_text(text, tokenizer)
        print(f"âœ… æ•°æ®é¢„å¤„ç†å™¨: æ–‡æœ¬å½¢çŠ¶ {result['tokens'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def check_forward_pass():
    """æ£€æŸ¥å‰å‘ä¼ æ’­"""
    print("\nğŸš€ æ£€æŸ¥å‰å‘ä¼ æ’­...")
    
    try:
        import torch
        from config.model_config import ModelConfig
        from src.models.multimodal_ai import MultiModalAI
        
        config = ModelConfig()
        model = MultiModalAI(config)
        model.eval()
        
        batch_size = 2
        seq_length = 10
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        text_tokens = torch.randint(0, config.vocab_size, (batch_size, seq_length))
        audio_features = torch.randn(batch_size, config.audio_seq_length, config.audio_feature_dim)
        video_frames = torch.randn(
            batch_size,
            config.image_channels,
            config.video_frames,
            config.image_height,
            config.image_width
        )
        
        # åˆ›å»ºæ©ç 
        text_mask = torch.ones(batch_size, seq_length)
        audio_mask = torch.ones(batch_size, config.audio_seq_length)
        vision_mask = torch.ones(batch_size, config.video_frames)
        
        print(f"âœ… è¾“å…¥å‡†å¤‡å®Œæˆ")
        print(f"  - æ–‡æœ¬: {text_tokens.shape}")
        print(f"  - éŸ³é¢‘: {audio_features.shape}")
        print(f"  - è§†é¢‘: {video_frames.shape}")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            output = model(
                text_tokens=text_tokens,
                audio_features=audio_features,
                video_frames=video_frames,
                image_data=None,
                text_mask=text_mask,
                audio_mask=audio_mask,
                vision_mask=vision_mask
            )
        
        # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶ï¼ˆå®é™…è¾“å‡ºå¯èƒ½æ˜¯ (batch_size, max_text_length) è€Œä¸æ˜¯ (batch_size, seq_length, vocab_size)ï¼‰
        print(f"å®é™…è¾“å‡ºå½¢çŠ¶: {output.shape}")
        assert len(output.shape) >= 2, f"è¾“å‡ºç»´åº¦ä¸è¶³: {output.shape}"
        assert output.shape[0] == batch_size, f"æ‰¹æ¬¡å¤§å°ä¸åŒ¹é…: {output.shape[0]} != {batch_size}"
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def check_device_compatibility():
    """æ£€æŸ¥è®¾å¤‡å…¼å®¹æ€§"""
    print("\nğŸ’» æ£€æŸ¥è®¾å¤‡å…¼å®¹æ€§...")
    
    try:
        import torch
        
        # æ£€æŸ¥CPU
        print(f"âœ… CPUå¯ç”¨")
        
        # æ£€æŸ¥CUDA
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨: {torch.cuda.get_device_name()}")
            print(f"âœ… CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
        else:
            print("â„¹ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        
        # æ£€æŸ¥MPS (Apple Silicon)
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            print("âœ… MPS (Apple Silicon) å¯ç”¨")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®¾å¤‡æ£€æŸ¥å¤±è´¥: {e}")
        return False


def check_file_structure():
    """æ£€æŸ¥æ–‡ä»¶ç»“æ„"""
    print("\nğŸ“ æ£€æŸ¥æ–‡ä»¶ç»“æ„...")
    
    required_files = [
        "src/models/multimodal_ai.py",
        "src/models/text_model.py",
        "src/models/audio_model.py",
        "src/models/vision_model.py",
        "src/models/fusion_model.py",
        "src/data/tokenizer.py",
        "src/data/dataset.py",
        "src/data/preprocessor.py",
        "src/api/chat_api.py",
        "src/api/server.py",
        "src/utils/logger.py",
        "src/utils/metrics.py",
        "src/utils/helpers.py",
        "config/model_config.py",
        "config/training_config.py",
        "tools/train.py",
        "tools/evaluate.py",
        "tools/inference.py",
        "tools/export_model.py",
        "requirements.txt",
        "setup.py",
        "README.md"
    ]
    
    missing_files = []
    for file_path in required_files:
        if not Path(file_path).exists():
            missing_files.append(file_path)
        else:
            print(f"âœ… {file_path}")
    
    if missing_files:
        print(f"\nâŒ ç¼ºå°‘æ–‡ä»¶:")
        for file_path in missing_files:
            print(f"  - {file_path}")
        return False
    
    print("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶éƒ½å­˜åœ¨")
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– å¤šæ¨¡æ€AIç³»ç»Ÿå®‰è£…éªŒè¯")
    print("=" * 50)
    
    checks = [
        ("æ–‡ä»¶ç»“æ„", check_file_structure),
        ("æ¨¡å—å¯¼å…¥", check_imports),
        ("è®¾å¤‡å…¼å®¹æ€§", check_device_compatibility),
        ("æ¨¡å‹åˆ›å»º", check_model_creation),
        ("æ•°æ®å¤„ç†", check_data_processing),
        ("å‰å‘ä¼ æ’­", check_forward_pass),
    ]
    
    results = []
    
    for check_name, check_func in checks:
        try:
            result = check_func()
            results.append((check_name, result))
        except Exception as e:
            print(f"âŒ {check_name} æ£€æŸ¥æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            results.append((check_name, False))
    
    # æ€»ç»“ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“‹ éªŒè¯ç»“æœæ€»ç»“:")
    
    passed = 0
    total = len(results)
    
    for check_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {check_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} é¡¹æ£€æŸ¥é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ­å–œï¼å¤šæ¨¡æ€AIç³»ç»Ÿå®‰è£…éªŒè¯å®Œå…¨é€šè¿‡ï¼")
        print("æ‚¨ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨ç³»ç»Ÿäº†ã€‚")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œ python tools/train.py å¼€å§‹è®­ç»ƒæ¨¡å‹")
        print("2. è¿è¡Œ python examples/basic_chat.py ä½“éªŒå¯¹è¯åŠŸèƒ½")
        print("3. è¿è¡Œ python -m src.api.server å¯åŠ¨WebæœåŠ¡")
    else:
        print(f"\nâš ï¸ æœ‰ {total - passed} é¡¹æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
        return 1
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
