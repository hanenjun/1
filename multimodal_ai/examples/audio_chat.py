#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘å¯¹è¯ç¤ºä¾‹
"""

import sys
import torch
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.api.chat_api import ChatAPI


def generate_mock_audio_features(duration_seconds=2.0, sample_rate=16000, feature_dim=128):
    """
    ç”Ÿæˆæ¨¡æ‹ŸéŸ³é¢‘ç‰¹å¾
    
    Args:
        duration_seconds: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        sample_rate: é‡‡æ ·ç‡
        feature_dim: ç‰¹å¾ç»´åº¦
    
    Returns:
        torch.Tensor: éŸ³é¢‘ç‰¹å¾å¼ é‡
    """
    # è®¡ç®—ç‰¹å¾åºåˆ—é•¿åº¦ï¼ˆå‡è®¾æ¯10msä¸€ä¸ªç‰¹å¾ï¼‰
    seq_length = int(duration_seconds * 100)  # 100 features per second
    
    # ç”Ÿæˆæ¨¡æ‹Ÿçš„éŸ³é¢‘ç‰¹å¾
    # è¿™é‡Œä½¿ç”¨éšæœºæ•°æ®ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥æ˜¯ä»éŸ³é¢‘æ–‡ä»¶æå–çš„ç‰¹å¾
    audio_features = torch.randn(seq_length, feature_dim)
    
    # æ·»åŠ ä¸€äº›æ¨¡å¼ä½¿å…¶æ›´åƒçœŸå®éŸ³é¢‘ç‰¹å¾
    # æ·»åŠ ä½é¢‘æˆåˆ†
    for i in range(0, seq_length, 10):
        audio_features[i:i+5] += torch.sin(torch.linspace(0, 2*np.pi, 5)).unsqueeze(1) * 0.5
    
    return audio_features


def simulate_different_audio_types():
    """æ¨¡æ‹Ÿä¸åŒç±»å‹çš„éŸ³é¢‘"""
    audio_types = {
        "éŸ³ä¹": {
            "features": generate_mock_audio_features(3.0, feature_dim=128),
            "description": "è¿™æ˜¯ä¸€æ®µéŸ³ä¹"
        },
        "è¯­éŸ³": {
            "features": generate_mock_audio_features(2.0, feature_dim=128),
            "description": "è¿™æ˜¯ä¸€æ®µè¯­éŸ³"
        },
        "ç¯å¢ƒéŸ³": {
            "features": generate_mock_audio_features(4.0, feature_dim=128),
            "description": "è¿™æ˜¯ç¯å¢ƒå£°éŸ³"
        },
        "åŠ¨ç‰©å«å£°": {
            "features": generate_mock_audio_features(1.5, feature_dim=128),
            "description": "è¿™æ˜¯åŠ¨ç‰©çš„å«å£°"
        }
    }
    return audio_types


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸµ å¤šæ¨¡æ€AIéŸ³é¢‘å¯¹è¯ç¤ºä¾‹")
    print("=" * 50)
    
    # æ¨¡å‹è·¯å¾„
    model_path = "checkpoints/multimodal_chat_model.pth"
    
    try:
        # åˆå§‹åŒ–èŠå¤©API
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        chat_api = ChatAPI(model_path)
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        model_info = chat_api.get_model_info()
        print(f"\næ¨¡å‹ä¿¡æ¯:")
        print(f"  æ¨¡å‹åç§°: {model_info['model_name']}")
        print(f"  å‚æ•°é‡: {model_info['total_parameters']:,}")
        print(f"  è®¾å¤‡: {model_info['device']}")
        
        # ç”Ÿæˆä¸åŒç±»å‹çš„éŸ³é¢‘æ ·æœ¬
        audio_samples = simulate_different_audio_types()
        
        print("\nå¯ç”¨çš„éŸ³é¢‘æ ·æœ¬:")
        for i, (audio_type, _) in enumerate(audio_samples.items(), 1):
            print(f"  {i}. {audio_type}")
        
        print("\nå¼€å§‹éŸ³é¢‘å¯¹è¯ (è¾“å…¥æ•°å­—é€‰æ‹©éŸ³é¢‘ç±»å‹, 'quit' é€€å‡º):")
        print("-" * 50)
        
        while True:
            # è·å–ç”¨æˆ·é€‰æ‹©
            user_input = input("\nè¯·é€‰æ‹©éŸ³é¢‘ç±»å‹ (1-4) æˆ–è¾“å…¥é—®é¢˜: ").strip()
            
            # æ£€æŸ¥é€€å‡ºå‘½ä»¤
            if user_input.lower() == 'quit':
                print("å†è§ï¼")
                break
            
            # è·³è¿‡ç©ºè¾“å…¥
            if not user_input:
                continue
            
            try:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—é€‰æ‹©
                if user_input.isdigit():
                    choice = int(user_input)
                    if 1 <= choice <= len(audio_samples):
                        audio_type = list(audio_samples.keys())[choice - 1]
                        audio_data = audio_samples[audio_type]
                        
                        print(f"\næ­£åœ¨åˆ†æ {audio_type} éŸ³é¢‘...")
                        
                        # å‘é€éŸ³é¢‘æ•°æ®è¿›è¡Œåˆ†æ
                        result = chat_api.chat_audio(
                            audio_features=audio_data["features"],
                            text_context=f"è¯·åˆ†æè¿™æ®µéŸ³é¢‘ï¼Œè¿™æ˜¯{audio_data['description']}",
                            max_length=100,
                            temperature=0.7
                        )
                        
                        if result['success']:
                            print(f"AIåˆ†æ: {result['response']}")
                        else:
                            print(f"é”™è¯¯: {result['error']}")
                    else:
                        print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-4ä¹‹é—´çš„æ•°å­—")
                
                else:
                    # ç”¨æˆ·è¾“å…¥çš„æ˜¯é—®é¢˜ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªéŸ³é¢‘æ ·æœ¬
                    audio_type = list(audio_samples.keys())[0]  # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ª
                    audio_data = audio_samples[audio_type]
                    
                    print(f"\næ­£åœ¨ç»“åˆéŸ³é¢‘å›ç­”é—®é¢˜...")
                    
                    result = chat_api.chat_audio(
                        audio_features=audio_data["features"],
                        text_context=user_input,
                        max_length=100,
                        temperature=0.8
                    )
                    
                    if result['success']:
                        print(f"AIå›å¤: {result['response']}")
                    else:
                        print(f"é”™è¯¯: {result['error']}")
                        
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—æˆ–é—®é¢˜")
            except Exception as e:
                print(f"å‘ç”Ÿé”™è¯¯: {e}")
        
        # æ˜¾ç¤ºå¯¹è¯å†å²
        history = chat_api.get_conversation_history()
        if history:
            print(f"\næœ¬æ¬¡å¯¹è¯å…± {len(history)} è½®:")
            for i, item in enumerate(history, 1):
                print(f"{i}. ç”¨æˆ·: {item['user']}")
                print(f"   AI: {item['ai']}")
    
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {model_path}")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹æ–‡ä»¶")
    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±è´¥: {e}")


def demo_audio_processing():
    """æ¼”ç¤ºéŸ³é¢‘å¤„ç†åŠŸèƒ½"""
    print("\nğŸ”Š éŸ³é¢‘å¤„ç†æ¼”ç¤º")
    print("-" * 30)
    
    # ç”Ÿæˆä¸åŒé•¿åº¦çš„éŸ³é¢‘ç‰¹å¾
    short_audio = generate_mock_audio_features(1.0)
    medium_audio = generate_mock_audio_features(3.0)
    long_audio = generate_mock_audio_features(5.0)
    
    print(f"çŸ­éŸ³é¢‘ç‰¹å¾å½¢çŠ¶: {short_audio.shape}")
    print(f"ä¸­ç­‰éŸ³é¢‘ç‰¹å¾å½¢çŠ¶: {medium_audio.shape}")
    print(f"é•¿éŸ³é¢‘ç‰¹å¾å½¢çŠ¶: {long_audio.shape}")
    
    # æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    print(f"\néŸ³é¢‘ç‰¹å¾ç»Ÿè®¡:")
    print(f"  å‡å€¼: {short_audio.mean():.4f}")
    print(f"  æ ‡å‡†å·®: {short_audio.std():.4f}")
    print(f"  æœ€å°å€¼: {short_audio.min():.4f}")
    print(f"  æœ€å¤§å€¼: {short_audio.max():.4f}")


if __name__ == '__main__':
    # è¿è¡Œä¸»ç¨‹åº
    main()
    
    # è¿è¡ŒéŸ³é¢‘å¤„ç†æ¼”ç¤º
    demo_audio_processing()
